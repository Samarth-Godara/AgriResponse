{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRM3 simulation code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9N-tXZHx7oM"
      },
      "source": [
        "# AgriResponse: simulation of RRM3 on the question bank\n",
        "\n",
        "Developer: Mr. Samarth Godara"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMkyIyCq9EnX"
      },
      "source": [
        "#for calculation of LD\n",
        "!pip install distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgFtiMLc1ofw"
      },
      "source": [
        "#for handling the knowledge base\n",
        "import pandas as pd\n",
        "#for calculation of LD\n",
        "import distance\n",
        "#for calculation of RRT\n",
        "import datetime\n",
        "#calculation of other mathematical operations\n",
        "import math\n",
        "#turning off the warnings\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTt5fGgEk84q"
      },
      "source": [
        "#creating geo-matrix\n",
        "#reading the geolocations of the centers of the states\n",
        "state_geo = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/state_geo.csv\")\n",
        "#print(state_geo.columns)\n",
        "state_geo_mat = pd.DataFrame()\n",
        "state_geo_mat['StateName']=state_geo['StateName']\n",
        "\n",
        "#calculating euclidean distance between each pair of states\n",
        "def geo_dist(geo_loc, st_geo):\n",
        "  x1= float(geo_loc.split(',')[0])\n",
        "  y1= float(geo_loc.split(',')[1])\n",
        "  x2= float(st_geo.split(',')[0])\n",
        "  y2= float(st_geo.split(',')[1])\n",
        "  d = math.sqrt(((x1-x2)**2)+((y1-y2)**2))\n",
        "  return d\n",
        "\n",
        "#creating geo-matrix\n",
        "for state in state_geo['StateName']:\n",
        "  st_geo = state_geo[state_geo['StateName']==state]['Geolocation'].iloc[0]\n",
        "  state_dist = state_geo.apply(lambda x : geo_dist(x['Geolocation'], st_geo), axis=1)\n",
        "  state_geo_mat[state]=state_dist\n",
        "\n",
        "#print(state_geo_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTC9Rv2Y19HR"
      },
      "source": [
        "#reading the knowledge base\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/kcc_dataset_processed.csv\")\n",
        "print(dataset.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxlYc5m2Flx"
      },
      "source": [
        "#module to remove unwanted spaces/tabs from the ends of crop names\n",
        "def strip_str(x):\n",
        "  try:\n",
        "    return x['Crop'].strip()\n",
        "  except:\n",
        "    return \"\"\n",
        "\n",
        "dataset['Crop']=dataset.apply(strip_str, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwmrFdsktEO7"
      },
      "source": [
        "#code of RRM3\n",
        "def model_3(crop, problem, state):\n",
        "  #obtain the sorted list of states in descending order of their distance with the input state\n",
        "  st_names = state_geo_mat.sort_values(state)['StateName']\n",
        "  #iteration of state switching\n",
        "  for st in st_names:\n",
        "    answers = model_2(crop, problem, st)\n",
        "    if len(answers)!=0:\n",
        "      print(\"Answers found in :\", st)\n",
        "      break\n",
        "    print(\"No Answers found in :\", st)\n",
        "\n",
        "  #returning the obtained answers\n",
        "  return answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfggKSgn34m4"
      },
      "source": [
        "#code of RRM2 - used by RRM3 internally\n",
        "def model_2(crop, problem, state):\n",
        "\n",
        "  #n-gram splitting module\n",
        "  def split_query(problem,x):\n",
        "    n_word = len(problem.split())\n",
        "    words = x['QueryText'].split()\n",
        "    word_bag = []\n",
        "    for i in range(len(words)-(n_word-1)):\n",
        "      word_bag.append(\" \".join(words[i:(i+n_word)]))\n",
        "    return word_bag\n",
        "\n",
        "  #LD calculating module\n",
        "  def l_match(x): \n",
        "    try:\n",
        "      word_list = split_query(problem,x)\n",
        "      problem_str=problem.lower()\n",
        "      for word in word_list:\n",
        "        if distance.levenshtein(problem_str, word.lower())<2:\n",
        "          return True\n",
        "      return False\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "  #state based filter\n",
        "  st_dataset = dataset[dataset['StateName']==state]\n",
        "  #crop based filter\n",
        "  crp_dataset = st_dataset[st_dataset['Crop']==crop]\n",
        "  #LD based filter\n",
        "  match = crp_dataset.apply(l_match, axis=1)\n",
        "  #print(\"Searching for the answers in the dataset...\")\n",
        "  ans_dataset = crp_dataset[match]\n",
        "\n",
        "  if ans_dataset.shape[0]==0:\n",
        "    #print(\"No answer found corresponding to the input disease...\")\n",
        "    return []\n",
        "\n",
        "  #answer-length based filter\n",
        "  ans_dataset[\"AnsLength\"]= ans_dataset[\"KccAns\"].str.len()\n",
        "  ans_dataset = ans_dataset[ans_dataset['AnsLength']<100]\n",
        "  ans_dataset.sort_values(by=['AnsLength'], ascending=False, inplace=True)\n",
        "\n",
        "  #returning all the retrieved answers\n",
        "  return ans_dataset['KccAns'].head(5).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apujPPzeoIpX",
        "outputId": "2f825d77-1077-45ef-9388-543ae3574dcc"
      },
      "source": [
        "#reading the question bank for the simulation\n",
        "query_bank = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank.csv\")\n",
        "print(query_bank.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Crop', 'Problem', 'State'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm5q24AkwKgi"
      },
      "source": [
        "#simulation code\n",
        "\n",
        "count = 1\n",
        "#ask question to the RRM3 iteratively\n",
        "def ask_quest(x):\n",
        "  global count\n",
        "  print(\"\\nQuestion #\",count)\n",
        "  count+=1\n",
        "\n",
        "  #note the starting and ending time to calculate the RTT\n",
        "  t1 = datetime.datetime.now()\n",
        "  answers = model_3(x['Crop'],x['Problem'],x['State'])\n",
        "  t2 = datetime.datetime.now()\n",
        "  t=t2-t1\n",
        "\n",
        "  print(\"Time consumed : \", t.total_seconds())\n",
        "  #print(\" Answers : \\n\", answers)\n",
        "\n",
        "  record = []\n",
        "  for answer in answers:\n",
        "    record.append(answer)\n",
        "  n_ans = len(answers)\n",
        "  while n_ans<5:\n",
        "    record.append(\"No answer\")\n",
        "    n_ans+=1\n",
        "  record.append(t.total_seconds())\n",
        "\n",
        "  #return the answers retrieved corresponding to the asked query\n",
        "  return record\n",
        "\n",
        "#run simulation\n",
        "ans_time = query_bank.apply(ask_quest, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asTapbwF1hmC"
      },
      "source": [
        "#saving the simulatino results in a dataframe - 5 answers and the RRT\n",
        "dummy = pd.DataFrame()\n",
        "\n",
        "for item in ans_time:\n",
        "  rec = {'Ans1':item[0],'Ans2':item[1],'Ans3':item[2],'Ans4':item[3],'Ans5':item[4],'Time':item[5]}\n",
        "  dummy=dummy.append(rec, ignore_index=True)\n",
        "\n",
        "output = pd.concat([query_bank, dummy], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpZwP6APKsw"
      },
      "source": [
        "#saving the simulation results in a file\n",
        "#output.to_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_3.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoRf8VnvPlrf"
      },
      "source": [
        "#reading the simulation results for calculation of metrics\n",
        "output = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_3.csv\")\n",
        "\n",
        "#calculate crop weightages\n",
        "crp_w = {}\n",
        "total = 0\n",
        "for crop in output.Crop.unique():\n",
        "  q_count=dataset[dataset['Crop']==crop].shape[0]\n",
        "  #print(crop,\" : \",q_count)\n",
        "  crp_w[crop]=q_count\n",
        "  total=total+q_count\n",
        "#print(\"Total queries : \", total)\n",
        "\n",
        "for crop in output.Crop.unique():\n",
        "  crp_w[crop]=(crp_w[crop]*1)/total\n",
        "\n",
        "#calculate CWPS for each question in the bank\n",
        "def crop_w_score(x):\n",
        "  if x['Ans1']!='No answer':\n",
        "    return crp_w[x['Crop']]/5\n",
        "  else:\n",
        "    return 0.0\n",
        "\n",
        "output['Crop_w_score']=output.apply(crop_w_score, axis=1)\n",
        "\n",
        "print(\"Crop-weighted score : \", output['Crop_w_score'].sum())\n",
        "\n",
        "#save simulation results with CWPS\n",
        "output.to_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_3_qws.csv\",index=False)\n",
        "#print(\"Crop-weighted score : \", output['Crop_w_score'].sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu3HC_aS9rMV"
      },
      "source": [
        "#show the accuracy results\n",
        "no_ans = output[output['Ans1']=='No answer']\n",
        "#no_ans['Crop'].unique()\n",
        "print(\"Unanswered Queries : \",no_ans.shape[0])\n",
        "print(\"Accuracy : \",(1-(no_ans.shape[0]/output.shape[0]))*100,\"%\")\n",
        "print(\"Mean query response time : \", output['Time'].mean(),\" Seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibV6ZQVvauTB"
      },
      "source": [
        "#display the frequency distribution of the RRT\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
        "plt.hist(output['Time'], bins=50)\n",
        "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}