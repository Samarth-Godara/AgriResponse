{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRM1 simulation code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0iAACccx2vB"
      },
      "source": [
        "# AgriResponse: simulation of RRM1 on the question bank\n",
        "\n",
        "Developer: Mr. Samarth Godara"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMkyIyCq9EnX"
      },
      "source": [
        "#for calculation of LD\n",
        "!pip install distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgFtiMLc1ofw"
      },
      "source": [
        "#for handling the knowledge base\n",
        "import pandas as pd\n",
        "#calculation of LD\n",
        "import distance\n",
        "#calculation of response-retrieval time\n",
        "import datetime\n",
        "#turning off the warnings\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTC9Rv2Y19HR"
      },
      "source": [
        "#reading the dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/kcc_dataset_processed.csv\")\n",
        "print(dataset.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxlYc5m2Flx"
      },
      "source": [
        "#string cleaning to remove any extra tabs/spaces at the ends of the crop names\n",
        "def strip_str(x):\n",
        "  try:\n",
        "    return x['Crop'].strip()\n",
        "  except:\n",
        "    return \"\"\n",
        "\n",
        "dataset['Crop']=dataset.apply(strip_str, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfggKSgn34m4"
      },
      "source": [
        "#code of RRM1\n",
        "def model_1(crop, problem):\n",
        "\n",
        "  #n-gram splitting function\n",
        "  def split_query(problem,x):\n",
        "    n_word = len(problem.split())\n",
        "    words = x['QueryText'].split()\n",
        "    word_bag = []\n",
        "    for i in range(len(words)-(n_word-1)):\n",
        "      word_bag.append(\" \".join(words[i:(i+n_word)]))\n",
        "    return word_bag\n",
        "\n",
        "  #LD filter\n",
        "  def l_match(x): \n",
        "    try:\n",
        "      word_list = split_query(problem,x)\n",
        "      problem_str=problem.lower()\n",
        "      for word in word_list:\n",
        "        if distance.levenshtein(problem_str, word.lower())<2:\n",
        "          return True\n",
        "      return False\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "  #crop name-based filter\n",
        "  crp_dataset = dataset[dataset['Crop']==crop]\n",
        "  #LD-based filter\n",
        "  match = crp_dataset.apply(l_match, axis=1)\n",
        "  #extracting remaining answer\n",
        "  ans_dataset = crp_dataset[match]\n",
        "\n",
        "  if ans_dataset.shape[0]==0:\n",
        "    print(\"No answer found corresponding to the input disease...\")\n",
        "    return []\n",
        "\n",
        "  #length-based filtering\n",
        "  ans_dataset[\"AnsLength\"]= ans_dataset[\"KccAns\"].str.len()\n",
        "  ans_dataset = ans_dataset[ans_dataset['AnsLength']<100]\n",
        "  #length-based sorting \n",
        "  ans_dataset.sort_values(by=['AnsLength'], ascending=False, inplace=True)\n",
        "\n",
        "  #answer output\n",
        "  return ans_dataset['KccAns'].head(5).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apujPPzeoIpX"
      },
      "source": [
        "#reading the question bank\n",
        "query_bank = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank.csv\")\n",
        "\n",
        "print(query_bank.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm5q24AkwKgi"
      },
      "source": [
        "#simulation code\n",
        "\n",
        "count = 1\n",
        "\n",
        "#ask question from the model, and record the responses\n",
        "def ask_quest(x):\n",
        "  global count\n",
        "  print(\"\\nQuestion #\",count)\n",
        "  count+=1\n",
        "  #note the starting and ending time - RRT\n",
        "  t1 = datetime.datetime.now()\n",
        "  answers = model_1(x['Crop'],x['Problem'])\n",
        "  t2 = datetime.datetime.now()\n",
        "  t=t2-t1\n",
        "\n",
        "  print(\"Time consumed : \", t.total_seconds())\n",
        "  #print(\" Answers : \\n\", answers)\n",
        "\n",
        "  record = []\n",
        "  for answer in answers:\n",
        "    record.append(answer)\n",
        "\n",
        "  n_ans = len(answers)\n",
        "  while n_ans<5:\n",
        "    record.append(\"No answer\")\n",
        "    n_ans+=1\n",
        "  record.append(t.total_seconds())\n",
        "\n",
        "  #return the retrieved answers corresponding to the input query\n",
        "  return record\n",
        "\n",
        "#run the simulation\n",
        "ans_time = query_bank.apply(ask_quest, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXQnPPR3yLBT"
      },
      "source": [
        "#sample tuple stored during the simulation - 5 answers and RRT in seconds\n",
        "ans_time[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asTapbwF1hmC"
      },
      "source": [
        "#storing the results in a separate file\n",
        "\n",
        "dummy = pd.DataFrame()\n",
        "\n",
        "for item in ans_time:\n",
        "  rec = {'Ans1':item[0],'Ans2':item[1],'Ans3':item[2],'Ans4':item[3],'Ans5':item[4],'Time':item[5]}\n",
        "  dummy=dummy.append(rec, ignore_index=True)\n",
        "\n",
        "output = pd.concat([query_bank, dummy], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siIdb3oyZEY9"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpZwP6APKsw"
      },
      "source": [
        "#saving the simulation results\n",
        "#output.to_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_1.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_cv_LRnAkKP"
      },
      "source": [
        "#reading the simulation results for calculation of AP and CWPS\n",
        "output = pd.read_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxk9SU8AhW-6"
      },
      "source": [
        "#calculation of crop weights\n",
        "crp_w = {}\n",
        "total = 0\n",
        "for crop in output.Crop.unique():\n",
        "  q_count=dataset[dataset['Crop']==crop].shape[0]\n",
        "  #print(crop,\" : \",q_count)\n",
        "  crp_w[crop]=q_count\n",
        "  total=total+q_count\n",
        "#print(\"Total queries : \", total)\n",
        "\n",
        "for crop in output.Crop.unique():\n",
        "  crp_w[crop]=(crp_w[crop]*1)/total\n",
        "\n",
        "crp_w_dataset = pd.DataFrame.from_dict(crp_w, orient='index', columns=['Weight'])\n",
        "\n",
        "#storing the crop weighted-score corresponding to each crops in a separate file\n",
        "crp_w_dataset.to_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/crop_weightage.csv\",index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYhhT6txWySA"
      },
      "source": [
        "#calculation of CWPS corresponding to each query\n",
        "def crop_w_score(x):\n",
        "  if x['Ans1']!='No answer':\n",
        "    return crp_w[x['Crop']]/5\n",
        "  else:\n",
        "    return 0.0\n",
        "\n",
        "#printing CWPS\n",
        "output['Crop_w_score']=output.apply(crop_w_score, axis=1)\n",
        "print(\"Crop-weighted score : \", output['Crop_w_score'].sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6bHWUXUoZVg"
      },
      "source": [
        "#storing the CWPS corresponding to each query along with the simulation results\n",
        "#output.to_csv(\"/content/drive/MyDrive/Research Backups/Project - NLP on KCC/Dataset/Question Bank_model_1.csv\",index=False)\n",
        "#print(\"Crop-weighted score : \", output['Crop_w_score'].sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqWcDpIBZlzS"
      },
      "source": [
        "no_ans = output[output['Ans1']=='No answer']\n",
        "print(\"Unanswered Queries : \",no_ans.shape[0])\n",
        "print(\"Accuracy : \",(1-(no_ans.shape[0]/output.shape[0]))*100,\"%\")\n",
        "print(\"Mean query response time : \", output['Time'].mean(),\" Seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibV6ZQVvauTB"
      },
      "source": [
        "#printing the frequency distribution histogram of the RRT\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
        "plt.hist(output['Time'], bins=50)\n",
        "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j78yGkiucu8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}